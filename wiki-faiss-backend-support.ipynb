{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-09-29T19:54:55.842869Z","iopub.execute_input":"2023-09-29T19:54:55.844175Z","iopub.status.idle":"2023-09-29T19:54:56.929972Z","shell.execute_reply.started":"2023-09-29T19:54:55.844127Z","shell.execute_reply":"2023-09-29T19:54:56.928225Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\n# installing offline dependencies\n!pip install -U /kaggle/input/faiss-gpu-173-python310/faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!cp -rf /kaggle/input/sentence-transformers-222/sentence-transformers /kaggle/working/sentence-transformers\n!pip install -U /kaggle/working/sentence-transformers\n!pip install -U /kaggle/input/blingfire-018/blingfire-0.1.8-py3-none-any.whl\n\n!pip install --no-index --no-deps /kaggle/input/llm-whls/transformers-4.31.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/peft-0.4.0-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/datasets-2.14.3-py3-none-any.whl\n!pip install --no-index --no-deps /kaggle/input/llm-whls/trl-0.5.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:54:56.938420Z","iopub.execute_input":"2023-09-29T19:54:56.939917Z","iopub.status.idle":"2023-09-29T19:55:46.896995Z","shell.execute_reply.started":"2023-09-29T19:54:56.939873Z","shell.execute_reply":"2023-09-29T19:55:46.895435Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install fastapi nest-asyncio pyngrok uvicorn\n!pip install accelerate bitsandbytes pydantic","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:55:46.899299Z","iopub.execute_input":"2023-09-29T19:55:46.899732Z","iopub.status.idle":"2023-09-29T19:56:08.510215Z","shell.execute_reply.started":"2023-09-29T19:55:46.899698Z","shell.execute_reply":"2023-09-29T19:56:08.508584Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\nfrom __future__ import annotations\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport torch\nimport ctypes\nlibc = ctypes.CDLL(\"libc.so.6\")","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:56:08.514531Z","iopub.execute_input":"2023-09-29T19:56:08.515165Z","iopub.status.idle":"2023-09-29T19:56:13.762470Z","shell.execute_reply.started":"2023-09-29T19:56:08.515116Z","shell.execute_reply":"2023-09-29T19:56:13.761310Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"SIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 16\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)\n\nmodel_dir = \"/kaggle/input/llm-se-debertav3-large\"","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:27:45.397915Z","iopub.execute_input":"2023-09-29T20:27:45.398330Z","iopub.status.idle":"2023-09-29T20:27:45.410453Z","shell.execute_reply.started":"2023-09-29T20:27:45.398297Z","shell.execute_reply":"2023-09-29T20:27:45.409012Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Fast API","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\nfrom __future__ import annotations\nfrom fastapi import FastAPI\nfrom pydantic import BaseModel, validator\nfrom fastapi.middleware.cors import CORSMiddleware\n\nimport os\nimport gc\nimport re\nfrom tqdm.auto import tqdm\nimport blingfire as bf\n\nfrom collections.abc import Iterable\n\nimport faiss\nfrom faiss import write_index, read_index\n\nfrom sentence_transformers import SentenceTransformer\n\nimport ctypes\n\nfrom peft import LoraConfig, get_peft_model\n\nfrom dataclasses import dataclass\nfrom typing import Optional, Union\n\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForMultipleChoice, TrainingArguments, Trainer\nfrom transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n\nSIM_MODEL = '/kaggle/input/sentencetransformers-allminilml6v2/sentence-transformers_all-MiniLM-L6-v2'\nDEVICE = 0\nMAX_LENGTH = 384\nBATCH_SIZE = 16\n\nWIKI_PATH = \"/kaggle/input/wikipedia-20230701\"\nwiki_files = os.listdir(WIKI_PATH)\n\nmodel_dir = \"/kaggle/input/llm-se-debertav3-large\"\n\nclass MCQ(BaseModel):\n    question: str\n    choices: list[str]\n\n    @validator(\"choices\")\n    def validate_choices_length(cls, choices):\n        min_length = 1  # Minimum allowed length\n        max_length = 5  # Maximum allowed length\n\n        if len(choices) < min_length:\n            raise ValueError(f\"Choices list must have at least {min_length} item(s)\")\n        if len(choices) > max_length:\n            raise ValueError(f\"Choices list can have at most {max_length} items\")\n\n        return choices\n\n    @validator(\"question\")\n    def validate_question_length(cls, question):\n        min_length = 1  # Minimum allowed length\n        max_length = 512  # Maximum allowed length\n\n        if len(question) < min_length:\n            raise ValueError(f\"Question must have at least {min_length} character(s)\")\n        if len(question) > max_length:\n            raise ValueError(f\"Question can have at most {max_length} characters\")\n\n        return question\n\n    \n# class SearchResult(BaseModel):\n#     search_score: list[float]\n#     search_index: list[int]\n\n\napp = FastAPI(\n    title=\"Scique API\",\n    description=\"An API to answer any MCQ from wikipedia without context and other questions with context.\",\n    version=\"0.1.0\",\n    docs_url=\"/docs\",\n    redoc_url=\"/redoc\",\n)\n\norigins = [\"http://localhost:8000\", \"localhost:8000\"]\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=origins,\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# eluwa_model: AutoModelForCausalLM | None = None\n# tokenizer: AutoTokenizer | None = None\n\nsentence_model: SentenceTransformer | None = None\nsentence_index: faiss.Index | None = None\n\n\n# load model artifacts on startup of the application to reduce latency\n@app.on_event(\"startup\")\nasync def startup_event():\n    global sentence_model, sentence_index\n\n    sentence_model = SentenceTransformer(SIM_MODEL, device=\"cuda\")\n    sentence_model.max_seq_length = MAX_LENGTH\n    sentence_model = sentence_model.half()  # half precision\n\n    sentence_index = read_index(\n        \"/kaggle/input/wikipedia-2023-07-faiss-index/wikipedia_202307.index\"\n    )\n\n\n@app.get(\"/\", tags=[\"root\"])\nasync def root() -> str:\n    return \"Welcome to Scique API!\"\n\n\n@app.put(\"/search_wiki/\", tags=[\"search_wiki\"])\nasync def ask_mcq(mcq: MCQ | None):\n    global sentence_model, sentence_index, wiki_parquet\n\n    # create string by joining the question and choices with a space separator\n#     question = mcq.question + \" \" + \" \".join(mcq.choices)\n    question = mcq.question\n\n    prompt_embeddings = sentence_model.encode(\n        [mcq.question],\n        batch_size=BATCH_SIZE,\n        device=DEVICE,\n        show_progress_bar=True,\n        convert_to_tensor=True,\n        normalize_embeddings=True,\n    )\n\n    prompt_embeddings = prompt_embeddings.detach().cpu().numpy()\n    _ = gc.collect()\n\n    ## Get the top 3 pages that are likely to contain the topic of interest\n    search_score, search_index = sentence_index.search(prompt_embeddings, 3)\n    \n    return search_score.tolist(), search_index.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:33:50.178710Z","iopub.execute_input":"2023-09-29T20:33:50.179187Z","iopub.status.idle":"2023-09-29T20:33:50.187829Z","shell.execute_reply.started":"2023-09-29T20:33:50.179154Z","shell.execute_reply":"2023-09-29T20:33:50.186638Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Overwriting main.py\n","output_type":"stream"}]},{"cell_type":"code","source":"!ngrok authtoken 2UZ3hYpFjXqzDaGMSCCib3aytam_5TZ46i8Au99qgkCcQwCQC","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:27:52.313219Z","iopub.execute_input":"2023-09-29T20:27:52.313971Z","iopub.status.idle":"2023-09-29T20:27:53.653111Z","shell.execute_reply.started":"2023-09-29T20:27:52.313930Z","shell.execute_reply":"2023-09-29T20:27:53.651563Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n","output_type":"stream"}]},{"cell_type":"code","source":"# !ngrok http --domain=hardy-lasting-ghost.ngrok-free.app 8000","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:11:18.136737Z","iopub.execute_input":"2023-09-29T20:11:18.137188Z","iopub.status.idle":"2023-09-29T20:11:18.142593Z","shell.execute_reply.started":"2023-09-29T20:11:18.137155Z","shell.execute_reply":"2023-09-29T20:11:18.141075Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import nest_asyncio\nimport subprocess\nimport uvicorn\n\n\n# specify a port\nport = 8000\n\n# Set your custom subdomain here\ncustom_subdomain = \"hardy-lasting-ghost.ngrok-free.app\"\n\n# Start the FastAPI app using uvicorn\nuvicorn_command = [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", str(port)]\nuvicorn_process = subprocess.Popen(uvicorn_command)\n\n# Run the ngrok command\nngrok_command = [\"ngrok\", \"http\", f\"--domain={custom_subdomain}\", str(port)]\nngrok_process = subprocess.Popen(ngrok_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n\nnest_asyncio.apply()\n\n# Wait for ngrok to generate the public URL\nngrok_output = ngrok_process.stdout.readline().strip()\nwhile \"ngrok.io\" not in ngrok_output:\n    ngrok_output = ngrok_process.stdout.readline().strip()\n\n# Display the public URL\nprint(\"Custom subdomain URL:\", ngrok_output)\n\ntry:\n    # Wait for the FastAPI app and ngrok processes to finish\n    uvicorn_process.wait()\n    ngrok_process.terminate()\nexcept KeyboardInterrupt:\n    # Handle keyboard interrupt gracefully\n    uvicorn_process.terminate()\n    ngrok_process.terminate()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import nest_asyncio\n# from pyngrok import ngrok\n# import uvicorn\n\n# # specify a port\n# port = 8000\n\n# # Set your custom subdomain here\n# custom_subdomain = \"scique\"\n\n# # Start ngrok with the custom subdomain\n# ngrok_tunnel = ngrok.connect(addr=\"8000\", proto=\"http\", hostname=custom_subdomain)\n\n# nest_asyncio.apply()\n\n# # where we can visit our FastAPI app\n# print('Custom subdomain URL:', ngrok_tunnel.public_url)\n\n# # finally run the app\n# uvicorn.run(app, port=port)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T20:11:11.037963Z","iopub.execute_input":"2023-09-29T20:11:11.039240Z","iopub.status.idle":"2023-09-29T20:11:11.046551Z","shell.execute_reply.started":"2023-09-29T20:11:11.039197Z","shell.execute_reply":"2023-09-29T20:11:11.043862Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# import nest_asyncio\n# from pyngrok import ngrok\n# import uvicorn\n\n# # specify a port\n# port = 8000\n# ngrok_tunnel = ngrok.connect(port)\n\n# nest_asyncio.apply()\n\n# # where we can visit our fastAPI app\n# print('Public URL:', ngrok_tunnel.public_url)\n\n# # finally run the app\n# uvicorn.run(app, port=port)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T19:56:24.403863Z","iopub.status.idle":"2023-09-29T19:56:24.405048Z","shell.execute_reply.started":"2023-09-29T19:56:24.404727Z","shell.execute_reply":"2023-09-29T19:56:24.404758Z"},"trusted":true},"execution_count":null,"outputs":[]}]}